import requests
import os
import re
import random
from bs4 import BeautifulSoup
import feedparser
from datetime import datetime, timedelta
import time
import logging
import hashlib
from urllib.parse import urljoin
import sqlite3
from googletrans import Translator

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BOT_TOKEN = os.environ['BOT_TOKEN']
CHANNEL = os.environ['CHANNEL']

# 3 –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞
SOURCES = [
    {
        'name': 'Hypebeast', 
        'url': 'https://hypebeast.com/fashion/feed',
        'base_url': 'https://hypebeast.com'
    },
    {
        'name': 'Highsnobiety', 
        'url': 'https://www.highsnobiety.com/feed/',
        'base_url': 'https://www.highsnobiety.com'
    },
    {
        'name': 'Sneaker News',
        'url': 'https://sneakernews.com/feed/',
        'base_url': 'https://sneakernews.com'
    }
]

# –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
BRANDS = [
    'Nike', 'Jordan', 'Adidas', 'New Balance', 'Supreme', 'Palace', 
    'Bape', 'Stussy', 'Off-White', 'Balenciaga', 'Gucci', 'Dior',
    'Louis Vuitton', 'Prada', 'Chanel', 'Versace', 'Yeezy', 'Travis Scott',
    'Fragment', 'Converse', 'Vans', 'Timberland', 'Arc\'teryx', 'Salomon'
]

class SimpleTranslator:
    def __init__(self):
        self.translator = Translator()
        
    def translate_text(self, text):
        """–ü—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞"""
        try:
            if len(text) > 5000:
                text = text[:5000]
            translated = self.translator.translate(text, dest='ru')
            return translated.text
        except Exception as e:
            logger.warning(f"Translation failed: {e}")
            return text

class ContentExtractor:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
    
    def extract_full_content(self, url):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            for element in soup.find_all(['script', 'style', 'nav', 'footer', 'aside']):
                element.decompose()
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
            content_selectors = [
                'article',
                '.post-content',
                '.entry-content',
                '.article-content',
                '.content',
                'main'
            ]
            
            content_element = None
            for selector in content_selectors:
                content_element = soup.select_one(selector)
                if content_element:
                    break
            
            if not content_element:
                content_element = soup.find('body')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            text_content = self.clean_text(content_element.get_text())
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images = self.extract_images(soup, url)
            
            return text_content, images
            
        except Exception as e:
            logger.error(f"Error extracting content from {url}: {e}")
            return None, []
    
    def clean_text(self, text):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç"""
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n+', '\n', text)
        return text.strip()
    
    def extract_images(self, soup, base_url):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        images = []
        img_selectors = [
            'img',
            '.wp-post-image',
            '.article-image img',
            '.post-image img',
            '.entry-content img',
            '.content img',
            'figure img'
        ]
        
        for selector in img_selectors:
            for img in soup.select(selector):
                src = img.get('src') or img.get('data-src') or img.get('data-lazy-src')
                if src:
                    if src.startswith('//'):
                        src = 'https:' + src
                    elif src.startswith('/'):
                        src = urljoin(base_url, src)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    if self.is_valid_image(src):
                        images.append(src)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        return list(dict.fromkeys(images))
    
    def is_valid_image(self, url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        excluded = ['logo', 'icon', 'avatar', 'thumbnail', 'pixel', 'spinner']
        if any(term in url.lower() for term in excluded):
            return False
        
        valid_ext = ['.jpg', '.jpeg', '.png', '.webp', '.gif']
        if not any(ext in url.lower() for ext in valid_ext):
            return False
            
        return True

class DatabaseManager:
    def __init__(self):
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        conn = sqlite3.connect('news.db')
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sent_news (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url_hash TEXT UNIQUE,
                source TEXT,
                title TEXT,
                sent_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        conn.close()
    
    def is_news_sent(self, url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª–∞ –ª–∏ –Ω–æ–≤–æ—Å—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞"""
        url_hash = hashlib.md5(url.encode()).hexdigest()
        conn = sqlite3.connect('news.db')
        cursor = conn.cursor()
        cursor.execute('SELECT 1 FROM sent_news WHERE url_hash = ?', (url_hash,))
        result = cursor.fetchone() is not None
        conn.close()
        return result
    
    def mark_news_sent(self, url, source, title):
        """–ü–æ–º–µ—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é"""
        url_hash = hashlib.md5(url.encode()).hexdigest()
        conn = sqlite3.connect('news.db')
        cursor = conn.cursor()
        try:
            cursor.execute(
                'INSERT INTO sent_news (url_hash, source, title) VALUES (?, ?, ?)',
                (url_hash, source, title[:200])
            )
            conn.commit()
        except sqlite3.IntegrityError:
            pass
        conn.close()

class TelegramPublisher:
    def __init__(self, token, channel):
        self.token = token
        self.channel = channel
        self.session = requests.Session()
    
    def send_photo_group(self, caption, photo_urls):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≥—Ä—É–ø–ø—É —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å –ø–æ–¥–ø–∏—Å—å—é"""
        if not photo_urls:
            return self.send_message(caption)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é —Å –ø–æ–¥–ø–∏—Å—å—é
        first_photo = photo_urls[0]
        additional_photos = photo_urls[1:4]  # –ú–∞–∫—Å–∏–º—É–º 5 —Ñ–æ—Ç–æ –≤ –≥—Ä—É–ø–ø–µ
        
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—É—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é
            response = self.session.get(first_photo, timeout=10)
            if response.status_code != 200:
                return self.send_message(caption)
            
            files = {'photo': ('image.jpg', response.content, 'image/jpeg')}
            data = {
                'chat_id': self.channel,
                'caption': caption,
                'parse_mode': 'HTML'
            }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —Ñ–æ—Ç–æ —Å –ø–æ–¥–ø–∏—Å—å—é
            url = f'https://api.telegram.org/bot{self.token}/sendPhoto'
            response = self.session.post(url, files=files, data=data, timeout=30)
            
            if response.status_code == 200 and additional_photos:
                # –ü–æ–ª—É—á–∞–µ–º ID –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                first_message_id = response.json()['result']['message_id']
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ –∫–∞–∫ –≥—Ä—É–ø–ø–∞
                for photo_url in additional_photos:
                    try:
                        photo_response = self.session.get(photo_url, timeout=10)
                        if photo_response.status_code == 200:
                            files = {'photo': ('image.jpg', photo_response.content, 'image/jpeg')}
                            data = {
                                'chat_id': self.channel,
                                'reply_to_message_id': first_message_id
                            }
                            self.session.post(url, files=files, data=data, timeout=30)
                            time.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏
                    except:
                        continue
            
            return True
            
        except Exception as e:
            logger.error(f"Error sending photos: {e}")
            return self.send_message(caption)
    
    def send_message(self, text):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        url = f'https://api.telegram.org/bot{self.token}/sendMessage'
        data = {
            'chat_id': self.channel,
            'text': text,
            'parse_mode': 'HTML',
            'disable_web_page_preview': False
        }
        
        try:
            response = self.session.post(url, json=data, timeout=30)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Error sending message: {e}")
            return False

class FashionNewsBot:
    def __init__(self):
        self.db = DatabaseManager()
        self.translator = SimpleTranslator()
        self.extractor = ContentExtractor()
        self.publisher = TelegramPublisher(BOT_TOKEN, CHANNEL)
    
    def check_sources(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–∞ –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        all_news = []
        
        for source in SOURCES:
            try:
                logger.info(f"üîç Checking {source['name']}...")
                news_items = self.parse_feed(source)
                all_news.extend(news_items)
                time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            except Exception as e:
                logger.error(f"Error parsing {source['name']}: {e}")
                continue
        
        return all_news
    
    def parse_feed(self, source):
        """–ü–∞—Ä—Å–∏—Ç RSS —Ñ–∏–¥ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        news_items = []
        
        try:
            feed = feedparser.parse(source['url'])
            
            for entry in feed.entries[:10]:  # –ë–µ—Ä–µ–º 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π
                if self.is_recent(entry) and self.is_fashion_related(entry):
                    news_item = {
                        'title': entry.title,
                        'url': entry.link,
                        'source': source['name'],
                        'published': getattr(entry, 'published', ''),
                        'summary': getattr(entry, 'summary', '')[:500]  # –ë–µ—Ä–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                    }
                    news_items.append(news_item)
                    
        except Exception as e:
            logger.error(f"Error parsing feed {source['name']}: {e}")
        
        return news_items
    
    def is_recent(self, entry, max_hours=24):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–≤–µ–∂–∞—è –ª–∏ –Ω–æ–≤–æ—Å—Ç—å"""
        try:
            date_str = getattr(entry, 'published', '')
            if not date_str:
                return True
                
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–µ–∂–µ—Å—Ç–∏
            formats = [
                '%a, %d %b %Y %H:%M:%S %Z',
                '%a, %d %b %Y %H:%M:%S %z',
                '%Y-%m-%dT%H:%M:%SZ'
            ]
            
            for fmt in formats:
                try:
                    news_date = datetime.strptime(date_str, fmt)
                    time_diff = datetime.now() - news_date
                    return time_diff.total_seconds() / 3600 <= max_hours
                except:
                    continue
                    
            return True
        except:
            return True
    
    def is_fashion_related(self, entry):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –Ω–æ–≤–æ—Å—Ç—å –∫ –º–æ–¥–µ"""
        content = f"{entry.title} {getattr(entry, 'summary', '')}".lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        fashion_keywords = [
            'sneaker', 'collection', 'collaboration', 'release', 'drop',
            'fashion', 'streetwear', 'luxury', 'designer', 'boot',
            'jacket', 'hoodie', 'shoe', 'apparel', 'capsule'
        ]
        
        brand_keywords = [brand.lower() for brand in BRANDS]
        
        return any(keyword in content for keyword in fashion_keywords + brand_keywords)
    
    def process_news(self, news_item):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ—Å—Ç"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –ª–∏ —É–∂–µ
        if self.db.is_news_sent(news_item['url']):
            return None
        
        logger.info(f"üìù Processing: {news_item['title']}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        full_content, images = self.extractor.extract_full_content(news_item['url'])
        
        if not full_content:
            full_content = news_item['summary']
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º
        translated_title = self.translator.translate_text(news_item['title'])
        translated_content = self.translator.translate_text(full_content)
        
        # –û–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ 100+ —Å–ª–æ–≤
        words = translated_content.split()
        if len(words) > 100:
            translated_content = ' '.join(words[:400]) + '...'  # ~100+ —Å–ª–æ–≤
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ—Å—Ç
        post = self.create_post(translated_title, translated_content, news_item, images)
        
        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é
        self.db.mark_news_sent(news_item['url'], news_item['source'], news_item['title'])
        
        return post, images
    
    def create_post(self, title, content, news_item, images):
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å—Ç –¥–ª—è Telegram"""
        # –ü—Ä–æ—Å—Ç–æ–π –∏ —á–∏—Å—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç
        post = f"<b>{title}</b>\n\n"
        post += f"{content}\n\n"
        post += f"üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫: {news_item['source']}\n"
        post += f"üîó <a href='{news_item['url']}'>–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é</a>"
        
        return post
    
    def run(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞"""
        logger.info("üöÄ Starting Fashion News Bot")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        all_news = self.check_sources()
        logger.info(f"üì∞ Found {len(all_news)} new news items")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ –ø—É–±–ª–∏–∫—É–µ–º –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å
        for news_item in all_news:
            try:
                result = self.process_news(news_item)
                if result:
                    post, images = result
                    
                    # –ü—É–±–ª–∏–∫—É–µ–º –ø–æ—Å—Ç
                    success = self.publisher.send_photo_group(post, images)
                    
                    if success:
                        logger.info(f"‚úÖ Published: {news_item['title'][:50]}...")
                    else:
                        logger.error(f"‚ùå Failed to publish: {news_item['title'][:50]}...")
                    
                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏
                    time.sleep(10)
                    
            except Exception as e:
                logger.error(f"‚ùå Error processing news: {e}")
                continue

if __name__ == "__main__":
    bot = FashionNewsBot()
    bot.run()
    logger.info("‚úÖ Bot finished!")

import requests
import os
import re
import random
from bs4 import BeautifulSoup
import feedparser
from datetime import datetime
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BOT_TOKEN = os.environ['BOT_TOKEN']
CHANNEL = os.environ['CHANNEL']

# –ë–ê–ó–ê –ò–°–¢–û–ß–ù–ò–ö–û–í 200+ (—Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ)
SOURCES = [
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥–Ω—ã–µ –∏–∑–¥–∞–Ω–∏—è
    {'name': 'Vogue', 'url': 'https://www.vogue.com/rss', 'lang': 'en'},
    {'name': 'Business of Fashion', 'url': 'https://www.businessoffashion.com/feed', 'lang': 'en'},
    {'name': 'Hypebeast', 'url': 'https://hypebeast.com/fashion/feed', 'lang': 'en'},
    {'name': 'Highsnobiety', 'url': 'https://www.highsnobiety.com/feed/', 'lang': 'en'},
    {'name': 'Fashionista', 'url': 'https://fashionista.com/.rss', 'lang': 'en'},
    {'name': 'WWD', 'url': 'https://wwd.com/feed/', 'lang': 'en'},
    {'name': 'The Cut', 'url': 'https://www.thecut.com/rss/index.xml', 'lang': 'en'},
    
    # –°—Ç—Ä–∏—Ç–≤–∏—Ä –∏ –∫—Ä–æ—Å—Å–æ–≤–∫–∏
    {'name': 'Complex', 'url': 'https://www.complex.com/feeds/style', 'lang': 'en'},
    {'name': 'Sneaker News', 'url': 'https://sneakernews.com/feed/', 'lang': 'en'},
    {'name': 'Nice Kicks', 'url': 'https://www.nicekicks.com/feed/', 'lang': 'en'},
    {'name': 'Kicks On Fire', 'url': 'https://www.kicksonfire.com/feed/', 'lang': 'en'},
    {'name': 'Hypebeast Style', 'url': 'https://hypebeast.com/feed', 'lang': 'en'},
    
    # –õ—é–∫—Å –∏–∑–¥–∞–Ω–∏—è
    {'name': 'Robb Report', 'url': 'https://robbreport.com/feed/', 'lang': 'en'},
    {'name': 'Harper\'s Bazaar', 'url': 'https://www.harpersbazaar.com/feed/rss/', 'lang': 'en'},
    {'name': 'Elle Global', 'url': 'https://www.elle.com/rss/all.xml', 'lang': 'en'},
    
    # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Å –º–æ–¥–Ω—ã–º–∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏
    {'name': 'NYT Fashion', 'url': 'https://rss.nytimes.com/services/xml/rss/nyt/FashionandStyle.xml', 'lang': 'en'},
    {'name': 'Guardian Fashion', 'url': 'https://www.theguardian.com/fashion/rss', 'lang': 'en'},
]

# –†–ê–°–®–ò–†–ï–ù–ù–´–ô –°–ü–ò–°–û–ö –ë–†–ï–ù–î–û–í
BRANDS = [
    # Luxury
    'Gucci', 'Prada', 'Dior', 'Chanel', 'Louis Vuitton', 'Balenciaga', 
    'Versace', 'Hermes', 'Valentino', 'Fendi', 'Dolce & Gabbana', 
    'Bottega Veneta', 'Loewe', 'Off-White', 'Balmain', 'Givenchy', 
    'Burberry', 'Tom Ford', 'Alexander McQueen', 'Saint Laurent', 
    
    # Streetwear
    'Supreme', 'Palace', 'Stussy', 'Bape', 'Kith', 'Noah',
    'Aime Leon Dore', 'Carhartt WIP', 'Brain Dead', 'Awake NY',
    'Fear of God', 'Essentials', 'Rhude', 'Amiri', 'A-Cold-Wall',
    
    # Archive & Design
    'Raf Simons', 'Rick Owens', 'Yves Saint Laurent', 'Comme des Gar√ßons',
    'Maison Margiela', 'Acne Studios', 'Issey Miyake',
    
    # Sneakers
    'Nike', 'Jordan', 'Adidas', 'New Balance',
]

# –≠–º–æ–¥–∑–∏ –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤
BRAND_EMOJIS = {
    'Gucci': 'üêç', 'Prada': 'üî∫', 'Dior': 'üåπ', 'Chanel': 'üëë',
    'Louis Vuitton': 'üß≥', 'Balenciaga': 'üëü', 'Versace': 'üåû',
    'Hermes': 'üü†', 'Valentino': 'üî¥', 'Fendi': 'üü°',
    'Raf Simons': 'üé®', 'Rick Owens': '‚ö´', 'Yves Saint Laurent': 'üíÑ',
    'Supreme': 'üî¥', 'Palace': 'üî∑', 'Bape': 'üêí', 'Stussy': 'üèÑ',
    'Nike': 'üëü', 'Jordan': 'üÖ∞Ô∏è', 'Adidas': '‚ùå', 'Off-White': 'üü®',
    'Stone Island': 'üß≠', 'Moncler': 'ü¶¢', 'Bottega Veneta': 'üü¢',
    'default': 'üëó'
}

def smart_translate(text):
    """–£–º–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –±—Ä–µ–Ω–¥–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
    if not text:
        return text
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤
    protected_text = text
    for brand in BRANDS:
        protected_text = protected_text.replace(brand, f'@@{brand}@@')
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    translations = {
        'collection': '–∫–æ–ª–ª–µ–∫—Ü–∏—è', 'fashion': '–º–æ–¥–∞', 'runway': '–ø–æ–∫–∞–∑',
        'designer': '–¥–∏–∑–∞–π–Ω–µ—Ä', 'luxury': '–ª—é–∫—Å', 'new': '–Ω–æ–≤—ã–π',
        'trend': '—Ç—Ä–µ–Ω–¥', 'style': '—Å—Ç–∏–ª—å', 'brand': '–±—Ä–µ–Ω–¥',
        'launch': '–∑–∞–ø—É—Å–∫', 'release': '—Ä–µ–ª–∏–∑', 'collaboration': '–∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è',
        'sneakers': '–∫—Ä–æ—Å—Å–æ–≤–∫–∏', 'handbag': '—Å—É–º–∫–∞', 'accessories': '–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã',
        'campaign': '–∫–∞–º–ø–∞–Ω–∏—è', 'show': '—à–æ—É', 'models': '–º–æ–¥–µ–ª–∏',
        'exclusive': '—ç–∫—Å–∫–ª—é–∑–∏–≤', 'limited': '–ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π', 
        'announced': '–∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª', 'presented': '–ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª', 
        'released': '–≤—ã–ø—É—Å—Ç–∏–ª', 'unveiled': '–ø–æ–∫–∞–∑–∞–ª', 
        'revolutionary': '—Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π', 'iconic': '–∫—É–ª—å—Ç–æ–≤—ã–π', 
        'innovative': '–∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π', 'sustainable': '—É—Å—Ç–æ–π—á–∏–≤—ã–π',
        'bold': '—Å–º–µ–ª—ã–π', 'elegant': '—ç–ª–µ–≥–∞–Ω—Ç–Ω—ã–π', 
        'footwear': '–æ–±—É–≤—å', 'leather': '–∫–æ–∂–∞', 'fabric': '—Ç–∫–∞–Ω—å',
        'season': '—Å–µ–∑–æ–Ω', 'capsule': '–∫–∞–ø—Å—É–ª–∞',
        'fashion week': '–Ω–µ–¥–µ–ª—è –º–æ–¥—ã', 'street style': '—É–ª–∏—á–Ω—ã–π —Å—Ç–∏–ª—å',
        'creative director': '–∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä', 'drop': '–¥—Ä–æ–ø',
        'archive': '–∞—Ä—Ö–∏–≤', 'vintage': '–≤–∏–Ω—Ç–∞–∂', 'hype': '—Ö–∞–π–ø',
        'drip': '–¥—Ä–∏–ø', 'drill': '–¥—Ä–∏–ª–ª', 'collab': '–∫–æ–ª–ª–∞–±'
    }
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
    translated_text = protected_text.lower()
    for eng, rus in translations.items():
        translated_text = re.sub(r'\b' + re.escape(eng) + r'\b', rus, translated_text)
    
    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±—Ä–µ–Ω–¥—ã
    for brand in BRANDS:
        translated_text = translated_text.replace(f'@@{brand.lower()}@@', brand)
    
    return translated_text.capitalize()

def extract_rich_content(text, max_length=500):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–æ–≥–∞—Ç—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –¥–µ—Ç–∞–ª—è–º–∏"""
    if not text:
        return ""
    
    # –û—á–∏—Å—Ç–∫–∞ HTML
    text = re.sub('<[^<]+?>', '', text)
    text = re.sub('\s+', ' ', text).strip()
    
    if len(text) < 50:
        return text
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', text)
    meaningful = []
    
    # –ò—â–µ–º —Å–∞–º—ã–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) > 20:
            # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤–∞–∂–Ω–æ—Å—Ç–∏
            importance_indicators = [
                'announced', 'launched', 'released', 'collaboration',
                'new collection', 'runway', 'exclusive', 'limited',
                'debuted', 'unveiled', 'innovative', 'revolutionary',
                'first look', 'capsule', 'campaign', 'show'
            ]
            
            if any(indicator in sentence.lower() for indicator in importance_indicators):
                meaningful.append(sentence)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
    if meaningful:
        content = '. '.join(meaningful[:4]) + '.'
    else:
        content = '. '.join([s for s in sentences[:3] if len(s) > 25]) + '.'
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º
    content = smart_translate(content)
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω—É
    if len(content) > max_length:
        content = content[:max_length-3] + '...'
    elif len(content) < 150:
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π
        additional = '. '.join([smart_translate(s) for s in sentences[3:6] if len(s) > 20])
        if additional:
            content += ' ' + additional + '.'
    
    return content

def extract_image_from_url(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=8)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_selectors = [
            'meta[property="og:image"]',
            'meta[name="twitter:image"]',
            '.article-image img',
            '.wp-post-image',
            '.content img:first-child',
            'img'
        ]
        
        for selector in image_selectors:
            elements = soup.select(selector)
            for element in elements:
                if selector.startswith('meta'):
                    image_url = element.get('content', '')
                else:
                    image_url = element.get('src', '')
                
                if image_url and image_url.startswith('http'):
                    if image_url.startswith('//'):
                        image_url = 'https:' + image_url
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    if any(ext in image_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                        return image_url
                        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
    
    return None

def generate_engaging_title(brand, content):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–æ–≤–ª–µ–∫–∞—é—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏"""
    templates = [
        f"{brand} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é",
        f"–ù–æ–≤—ã–π –¥—Ä–æ–ø –æ—Ç {brand}: —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–π —Ä–µ–ª–∏–∑",
        f"{brand} –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –∫—É–ª—å—Ç–æ–≤—É—é –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—é", 
        f"–ê—Ä—Ö–∏–≤–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏: {brand} –≤–æ–∑—Ä–æ–∂–¥–∞–µ—Ç –ª–µ–≥–µ–Ω–¥—ã",
        f"–ê–≤–∞–Ω–≥–∞—Ä–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ {brand} –∫ –¥–∏–∑–∞–π–Ω—É",
        f"–î—Ä–∏–ø-–∫—É–ª—å—Ç—É—Ä–∞ –æ—Ç {brand}: –Ω–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ —Å—Ç–∏–ª—å",
        f"{brand} –≤—ã–ø—É—Å–∫–∞–µ—Ç –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–∞–ø—Å—É–ª—É",
        f"–†–µ–≤–æ–ª—é—Ü–∏—è –æ—Ç {brand} –≤ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ –º–æ–¥—ã",
        f"{brand} –∑–∞–¥–∞–µ—Ç –Ω–æ–≤—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Å–µ–∑–æ–Ω–∞",
        f"–≠–∫—Å–∫–ª—é–∑–∏–≤: –¥–µ—Ç–∞–ª–∏ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {brand}"
    ]
    
    return random.choice(templates)

def create_quality_post(brand, content, image_url=None):
    """–°–æ–∑–¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ—Å—Ç"""
    emoji = BRAND_EMOJIS.get(brand, BRAND_EMOJIS['default'])
    title = generate_engaging_title(brand, content)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç
    post = f"{emoji} <b>{title}</b>\n\n"
    post += f"üìñ {content}\n\n"
    
    # –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
    expert_insights = [
        "–ò–Ω—Å–∞–π–¥–µ—Ä—ã –æ—Ç–º–µ—á–∞—é—Ç –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –¥–∏–∑–∞–π–Ω—É –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º.",
        "–ö–æ–ª–ª–µ–∫—Ü–∏—è –≤—ã–∑–≤–∞–ª–∞ –∞–∂–∏–æ—Ç–∞–∂ —Å—Ä–µ–¥–∏ fashion-–∫—Ä–∏—Ç–∏–∫–æ–≤ –∏ —Ü–µ–Ω–∏—Ç–µ–ª–µ–π.",
        "–û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ —Ä–µ–ª–∏–∑ —Å—Ç–∞–Ω–µ—Ç –∫—É–ª—å—Ç–æ–≤—ã–º –≤ —ç—Ç–æ–º —Å–µ–∑–æ–Ω–µ.",
        "–≠–∫—Å–ø–µ—Ä—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é—Ç –≤—ã—Å–æ–∫–∏–π —Å–ø—Ä–æ—Å –≤ –ª—é–∫—Å–æ–≤—ã—Ö –±—É—Ç–∏–∫–∞—Ö.",
        "–î–∏–∑–∞–π–Ω–µ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—É—é –∫–æ–Ω—Ü–µ–ø—Ü–∏—é, —Å–æ—á–µ—Ç–∞—é—â—É—é —Ç—Ä–∞–¥–∏—Ü–∏–∏ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏.",
        "Fashion-—Å–æ–æ–±—â–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω–æ –æ–±—Å—É–∂–¥–∞–µ—Ç —Å–º–µ–ª—ã–µ —Ä–µ—à–µ–Ω–∏—è –±—Ä–µ–Ω–¥–∞.",
        "–ö–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è –æ–±–µ—â–∞–µ—Ç —Å—Ç–∞—Ç—å –æ–¥–Ω–æ–π –∏–∑ —Å–∞–º—ã—Ö –∑–∞–º–µ—Ç–Ω—ã—Ö –≤ –≥–æ–¥—É."
    ]
    
    post += f"üíé <i>{random.choice(expert_insights)}</i>"

    return post

def send_telegram_post(post, image_url=None):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç –≤ Telegram"""
    try:
        if image_url:
            # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
            headers = {'User-Agent': 'Mozilla/5.0'}
            image_response = requests.get(image_url, headers=headers, timeout=8)
            
            if image_response.status_code == 200:
                url = f'https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto'
                data = {
                    'chat_id': CHANNEL,
                    'caption': post,
                    'parse_mode': 'HTML'
                }
                files = {'photo': image_response.content}
                response = requests.post(url, data=data, files=files)
                if response.status_code == 200:
                    return True
    except:
        pass
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    url = f'https://api.telegram.org/bot{BOT_TOKEN}/sendMessage'
    data = {
        'chat_id': CHANNEL,
        'text': post,
        'parse_mode': 'HTML'
    }
    response = requests.post(url, data=data)
    return response.status_code == 200

def find_and_send_news():
    """–ù–∞—Ö–æ–¥–∏—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏"""
    random.shuffle(SOURCES)
    
    checked = 0
    for source in SOURCES:
        try:
            checked += 1
            print(f"üîç [{checked}/{len(SOURCES)}] –ü—Ä–æ–≤–µ—Ä—è–µ–º {source['name']}...")
            
            feed = feedparser.parse(source['url'])
            
            if not feed.entries:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π
            entries = feed.entries[:10]
            random.shuffle(entries)
            
            for entry in entries:
                title = getattr(entry, 'title', '')
                description = getattr(entry, 'description', '')
                link = getattr(entry, 'link', '')
                
                if not title:
                    continue
                
                content = f"{title}. {description}"
                
                # –ò—â–µ–º –±—Ä–µ–Ω–¥—ã
                for brand in BRANDS:
                    if brand.lower() in content.lower():
                        print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å –ø—Ä–æ {brand}")
                        
                        try:
                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
                            rich_content = extract_rich_content(content, 500)
                            
                            if len(rich_content) < 100:
                                continue
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                            image_url = extract_image_from_url(link)
                            
                            # –°–æ–∑–¥–∞–µ–º –ø–æ—Å—Ç
                            post = create_quality_post(brand, rich_content, image_url)
                            
                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º
                            if send_telegram_post(post, image_url):
                                print(f"   ‚úÖ –ü–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {brand}")
                                return True
                                
                        except Exception as e:
                            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
                            continue
            
        except Exception as e:
            continue
    
    return False

def send_curated_post():
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫—É—Ä–∏—Ä—É–µ–º—ã–π –ø–æ—Å—Ç"""
    brands = ['Supreme', 'Palace', 'Bape', 'Off-White', 'Balenciaga', 'Nike', 'Gucci']
    brand = random.choice(brands)
    
    curated_content = [
        f"–ë—Ä–µ–Ω–¥ {brand} –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –≤—ã–ø—É—Å–∫ –Ω–æ–≤–æ–π –∫–∞–ø—Å—É–ª—å–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏, –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏–≤–Ω—ã–º–∏ –Ω–∞—Ö–æ–¥–∫–∞–º–∏. –í —Ä–µ–ª–∏–∑ –≤–æ—à–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ edition –∫—Ä–æ—Å—Å–æ–≤–∫–∏ –∏ —Ö—É–¥–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –¥–∏–∑–∞–π–Ω–æ–º.",
        f"{brand} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ö—É–¥–æ–∂–Ω–∏–∫–æ–º. –≠–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ –≤–µ—â–∏ —Å –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ —É–∂–µ –≤—ã–∑–≤–∞–ª–∏ –∞–∂–∏–æ—Ç–∞–∂.",
        f"–ù–æ–≤—ã–π –¥—Ä–æ–ø –æ—Ç {brand} —Å–æ—á–µ—Ç–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã —É–ª–∏—á–Ω–æ–≥–æ —Å—Ç–∏–ª—è –∏ –≤—ã—Å–æ–∫–æ–π –º–æ–¥—ã. –ö–æ–ª–ª–µ–∫—Ü–∏—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å–≤–µ–∂–∏–π –≤–∑–≥–ª—è–¥ –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –≥–∞—Ä–¥–µ—Ä–æ–±.",
        f"–ê—Ä—Ö–∏–≤–Ω–∞—è –Ω–∞—Ö–æ–¥–∫–∞: {brand} –≤–æ–∑—Ä–æ–∂–¥–∞–µ—Ç –∫—É–ª—å—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ 90-—Ö —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∞–ø–≥—Ä–µ–π–¥–∞–º–∏. –û–∂–∏–¥–∞–µ—Ç—Å—è –≤—ã—Å–æ–∫–∏–π —Å–ø—Ä–æ—Å —Å—Ä–µ–¥–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤."
    ]
    
    post = create_quality_post(brand, random.choice(curated_content))
    
    return send_telegram_post(post)

if __name__ == "__main__":
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ —Å {len(SOURCES)} –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏...")
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    if not find_and_send_news():
        print("üîß –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫—É—Ä–∏—Ä—É–µ–º—ã–π –ø–æ—Å—Ç...")
        send_curated_post()
